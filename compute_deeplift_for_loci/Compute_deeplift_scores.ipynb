{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln: failed to create symbolic link './hg19.chrom.sizes': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!ln -s /mnt/data/annotations/by_release/hg19/hg19.chrom.sizes ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "for idx in 0 1 2 3 4 5; do\n",
    "    bedfile=\"../coordinates/coordinates_\"$idx\".bed\"\n",
    "    cat $bedfile | perl -lane 'print $F[0].\"\\t\".($F[1]+$F[9]-500).\"\\t\".($F[1]+$F[9]+500)' > expanded_coordinates_$idx.bed\n",
    "    bedtools getfasta -fi /mnt/data/annotations/by_release/hg19/male.hg19.fa -bed expanded_coordinates_$idx.bed > expanded_coordinates_$idx.fa\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,1,2,3,4,5]\n",
    "fastafiles = [\"expanded_coordinates_\"+str(idx)+\".fa\" for idx in indices]\n",
    "model_hdf5 = \"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/regression/DNASE.K562.regressionlabels.allbins.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#this is set up for 1d convolutions where examples\n",
    "#have dimensions (len, num_channels)\n",
    "#the channel axis is the axis for one-hot encoding.\n",
    "def one_hot_encode_along_channel_axis(sequence):\n",
    "    to_return = np.zeros((len(sequence),4), dtype=np.int8)\n",
    "    seq_to_one_hot_fill_in_array(zeros_array=to_return,\n",
    "                                 sequence=sequence, one_hot_axis=1)\n",
    "    return to_return\n",
    "\n",
    "def seq_to_one_hot_fill_in_array(zeros_array, sequence, one_hot_axis):\n",
    "    assert one_hot_axis==0 or one_hot_axis==1\n",
    "    if (one_hot_axis==0):\n",
    "        assert zeros_array.shape[1] == len(sequence)\n",
    "    elif (one_hot_axis==1): \n",
    "        assert zeros_array.shape[0] == len(sequence)\n",
    "    #will mutate zeros_array\n",
    "    for (i,char) in enumerate(sequence):\n",
    "        if (char==\"A\" or char==\"a\"):\n",
    "            char_idx = 0\n",
    "        elif (char==\"C\" or char==\"c\"):\n",
    "            char_idx = 1\n",
    "        elif (char==\"G\" or char==\"g\"):\n",
    "            char_idx = 2\n",
    "        elif (char==\"T\" or char==\"t\"):\n",
    "            char_idx = 3\n",
    "        elif (char==\"N\" or char==\"n\"):\n",
    "            continue #leave that pos as all 0's\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported character: \"+str(char))\n",
    "        if (one_hot_axis==0):\n",
    "            zeros_array[char_idx,i] = 1\n",
    "        elif (one_hot_axis==1):\n",
    "            zeros_array[i,char_idx] = 1\n",
    "\n",
    "sequences_sets = [[x[1].rstrip() for x in enumerate(open(fastafile)) if x[0]%2==1]\n",
    "                  for fastafile in fastafiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nonlinear_mxts_mode is set to: Rescale\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n",
      "Heads-up: current implementation assumes maxpool layer is followed by a linear transformation (conv/dense layer)\n"
     ]
    }
   ],
   "source": [
    "import deeplift\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "from deeplift.util import get_shuffle_seq_ref_function\n",
    "from deeplift.dinuc_shuffle import dinuc_shuffle\n",
    "\n",
    "deeplift_model =\\\n",
    "    kc.convert_model_from_saved_files(\n",
    "        model_hdf5,\n",
    "        nonlinear_mxts_mode=deeplift.layers.NonlinearMxtsMode.Rescale)\n",
    "deeplift_contribs_func = deeplift_model.get_target_contribs_func(\n",
    "                            find_scores_layer_idx=0,\n",
    "                            target_layer_idx=-1)\n",
    "onehot_func = lambda x: np.array([one_hot_encode_along_channel_axis(seq)[None,:,:] for seq in x])\n",
    "scoring_func = get_shuffle_seq_ref_function(\n",
    "    #score_computation_function is the original function to compute scores\n",
    "    score_computation_function=deeplift_contribs_func,\n",
    "    #shuffle_func is the function that shuffles the sequence\n",
    "    #technically, given the background of this simulation, randomly_shuffle_seq\n",
    "    #makes more sense. However, on real data, a dinuc shuffle is advisable due to\n",
    "    #the strong bias against CG dinucleotides\n",
    "    shuffle_func=dinuc_shuffle,\n",
    "    one_hot_func=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 reference seqs generated\n",
      "2000 reference seqs generated\n",
      "3000 reference seqs generated\n",
      "4000 reference seqs generated\n",
      "5000 reference seqs generated\n",
      "6000 reference seqs generated\n",
      "7000 reference seqs generated\n",
      "8000 reference seqs generated\n",
      "9000 reference seqs generated\n",
      "10000 reference seqs generated\n",
      "11000 reference seqs generated\n",
      "12000 reference seqs generated\n",
      "13000 reference seqs generated\n",
      "14000 reference seqs generated\n",
      "15000 reference seqs generated\n",
      "16000 reference seqs generated\n"
     ]
    }
   ],
   "source": [
    "for idx,sequences in enumerate(sequences_sets):\n",
    "    onehot = onehot_func(sequences)\n",
    "    deeplift_scores = scoring_func(\n",
    "        task_idx=0,\n",
    "        input_data_sequences=onehot,\n",
    "        num_refs_per_seq=10,\n",
    "        batch_size=200,\n",
    "        progress_update=1000)\n",
    "    print(deeplift_scores.shape)\n",
    "    onehot = np.squeeze(onehot)\n",
    "    deeplift_scores = np.squeeze(deeplift_scores)\n",
    "    projected_deeplift = np.sum(deeplift_scores, axis=-1)[:,:,None]*onehot\n",
    "    print(projected_deeplift.shape)\n",
    "    np.save(\"deeplift_scores_\"+str(idx)+\".npy\", projected_deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
