{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kundajelab/locusselect/blob/master/examples/regression%20on%20200%20bp%20genome%20bins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlqtDJn5vLs4"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.random import seed\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import manifold\n",
    "from apricot import FacilityLocationSelection\n",
    "from apricot import FeatureBasedSelection\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import umap\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import locusselect \n",
    "from locusselect.embeddings import * \n",
    "from locusselect.deeplift import * \n",
    "from locusselect.utils import *\n",
    "import os\n",
    "import pickle\n",
    "from pybedtools import BedTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_transform(peak_data, n_components=3, random_state=25, metric = 'correlation',n_neighbors=15,min_dist=0.1):\n",
    "    umap_obj = umap.UMAP(n_components=n_components, random_state=random_state,\n",
    "        min_dist=min_dist,metric=metric,n_neighbors=n_neighbors)\n",
    "    try:\n",
    "        umap_res = umap_obj.fit_transform(peak_data.toarray())\n",
    "    except:\n",
    "        umap_res = umap_obj.fit_transform(peak_data)\n",
    "    return umap_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performEmbeddings ( data_list, n_components=2, random_state=2, metric= 'correlation' ) :\n",
    "    embedding_list = []; \n",
    "    for data in data_list :\n",
    "        embedding_list.append( umap_transform(data, n_components=2, random_state=2,metric=distanceMeasure) )\n",
    "    return (embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGeneralAnnotation ( Ind_list, label_list, k ) :\n",
    "    num_labels = np.zeros(k)\n",
    "    \n",
    "    label_dict = { 'All' : 0 }\n",
    "    for i in range(len(Ind_list)) :\n",
    "        num_labels[Ind_list[i]] = i + 1\n",
    "        label_dict[label_list[i]] = i + 1\n",
    "    return (num_labels, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_2d(embedding, num_labels=None, label_dict=None, s_dict=None, a_dict=None, cmap=None, norm=None, title='' ):\n",
    "    fig = plt.figure(figsize=(7,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    if num_labels is None or label_dict is None :\n",
    "        scatter_res = ax.scatter(embedding[:,0], embedding[:,1], s=4, alpha=1)\n",
    "\n",
    "    else :\n",
    "        for label in label_dict.keys() :\n",
    "            Ind = np.where(num_labels == label_dict[label])[0]\n",
    "            color = cm.jet(label_dict[label] / float(len(label_dict.keys()) - 1))\n",
    "            if s_dict is None : \n",
    "                dotsize = 4 \n",
    "            else : \n",
    "                dotsize = s_dict[label]\n",
    "            if a_dict is None : \n",
    "                alpha = 1\n",
    "            else : \n",
    "                alpha = a_dict[label]\n",
    "            scatter_res = ax.scatter(embedding[Ind,0], embedding[Ind,1], s=dotsize, alpha=alpha,c=color, label=label)\n",
    "        ax.set_xlim( min(embedding[:,0]) - ( ( max(embedding[:,0]) - min(embedding[:,0]) ) * 0.5 ), max(embedding[:,0]) )\n",
    "        ax.set_ylim( min(embedding[:,1]), max(embedding[:,1]) + ( ( max(embedding[:,1]) - min(embedding[:,1]) ) * 0.5 ) )\n",
    "        ax.set_title(title)\n",
    "        ax.legend(loc='upper left',prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectSubset ( data_matrix, n = None, distance = 'euclidean', initial_subset = None, selection_subset = None ) :\n",
    "    if selection_subset is not None :\n",
    "        data_matrix = data_matrix[selection_subset]\n",
    "    \n",
    "    if n is None :\n",
    "        n = np.shape(data_matrix)[0]\n",
    "    \n",
    "    if initial_subset is None :\n",
    "        model = FacilityLocationSelection(n, distance)\n",
    "    else :\n",
    "        model = FacilityLocationSelection(n, distance, initial_subset = initial_subset )\n",
    "    \n",
    "    Xi = model.fit_transform(data_matrix)\n",
    "    SubsetInd = model.ranking\n",
    "    Gains = model.gains\n",
    "    \n",
    "    if selection_subset is not None :\n",
    "        SubsetInd = selection_subset[SubsetInd]\n",
    "    \n",
    "    return SubsetInd, Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeBed(labels) :\n",
    "    chrNames = np.array([ (coords.decode()).split('_')[0] for coords in labels ] )\n",
    "    starts = np.array ([ int((coords.decode()).split('_')[1]) for coords in labels ] )\n",
    "    ends = np.array ([ int((coords.decode()).split('_')[2]) for coords in labels ] )\n",
    "    \n",
    "    table = np.zeros(len(chrNames), dtype={'names':('f0', 'f1', 'f2'),'formats':('S5', 'i4', 'i4')})\n",
    "    table['f0'] = chrNames; table['f1'] = starts+1; table['f2'] = ends;\n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersectBeds ( bed1, bed2, pickLargestOverlap = True ) :\n",
    "    chrs1 = np.unique(bed1['f0']);  chrs2 = np.unique(bed2['f0'])\n",
    "    allchrs = np.intersect1d(chrs1,chrs2)\n",
    "    overlapInd1 = []; overlapInd2 = []; overlapLen = []\n",
    "    for chr in allchrs :\n",
    "        Ind1 = np.where(bed1['f0']==chr)[0];    Ind2 = np.where(bed2['f0']==chr)[0]\n",
    "        midPoint1 = ( bed1['f2'][Ind1] + bed1['f1'][Ind1] ) / 2\n",
    "        midPoint2 = ( bed2['f2'][Ind2] + bed2['f1'][Ind2] ) / 2\n",
    "        int1 = bed1['f2'][Ind1] - bed1['f1'][Ind1] + 1\n",
    "        int2 = bed2['f2'][Ind2] - bed2['f1'][Ind2] + 1\n",
    "        maxInt = 2 * np.max(np.append(int1,int2))\n",
    "        for I in range(len(Ind1)) :\n",
    "            dist = np.abs( midPoint1[I] - midPoint2 )\n",
    "            closeInd = Ind2[ np.where( dist < maxInt )[0] ]\n",
    "            if len(closeInd) > 0 :\n",
    "                for I2 in closeInd :\n",
    "                    maxStart = max(bed1[Ind1[I]][1], bed2[I2][1])\n",
    "                    minEnd = min(bed1[Ind1[I]][2], bed2[I2][2])\n",
    "                    if maxStart < minEnd:\n",
    "                        overlapInd1.append(Ind1[I])\n",
    "                        overlapInd2.append(I2)\n",
    "                        overlapLen.append(minEnd-maxStart)\n",
    "                        \n",
    "    overlapInd1 = np.array(overlapInd1); overlapInd2 = np.array(overlapInd2); overlapLen = np.array(overlapLen)\n",
    "    \n",
    "    uniqueOverlapInd1 = []; uniqueOverlapInd2 = []; uniqueOverlapLen = []\n",
    "    if pickLargestOverlap == True :\n",
    "        uniqueOI1 = np.unique(overlapInd1)\n",
    "        for uI in uniqueOI1 :\n",
    "            Ind = np.where(overlapInd1==uI)[0]\n",
    "            Ord = np.argsort(overlapLen[Ind])\n",
    "            uniqueOverlapInd1.append(uI); uniqueOverlapInd2.append(overlapInd2[Ind[Ord[-1]]]);\n",
    "            uniqueOverlapLen.append(overlapLen[Ind[Ord[-1]]])\n",
    "    \n",
    "    uniqueOverlapInd1 = np.array(uniqueOverlapInd1); uniqueOverlapInd2 = np.array(uniqueOverlapInd2)\n",
    "    uniqueOverlapLen = np.array(uniqueOverlapLen)\n",
    "    \n",
    "    return (uniqueOverlapInd1,uniqueOverlapInd2,uniqueOverlapLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_data_list_fc(bed_list, layer):\n",
    "\n",
    "    dl_fc_data_list = []\n",
    "    \n",
    "    for bed_file in bed_list:\n",
    "        \n",
    "        print(bed_file)\n",
    "        print(layer)\n",
    "        \n",
    "        all_fc_embeddings = []\n",
    "\n",
    "        fc_embedding_args={\"input_bed_file\":bed_file,\n",
    "                   \"model_hdf5\":\"/data/locusselect/k562_dnase_dl_models/k562_classification/DNASE.K562.classification.SummitWithin200bpCenter.0\",\n",
    "                   \"ref_fasta\":\"/data/refs/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":True,\n",
    "                   \"flank\":500,\n",
    "                   \"embedding_layer\":layer,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20}\n",
    "        fc_regions, fc_embeddings = compute_embeddings(fc_embedding_args)\n",
    "        np.savez_compressed(bed_file.split('/')[-1]+'.fc.npz',bed_entries=fc_regions,fc_scores=fc_embeddings)\n",
    "        \n",
    "        dl_fc_data_list.append(fc_embeddings)\n",
    "        \n",
    "    return dl_fc_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_data_list_conv(bed_list, layer):\n",
    "\n",
    "    dl_fc_data_list = []\n",
    "    \n",
    "    for bed_file in bed_list:\n",
    "        \n",
    "        print(bed_file)\n",
    "        print(layer)\n",
    "        all_fc_embeddings = []\n",
    "\n",
    "        fc_embedding_args={\"input_bed_file\":bed_file,\n",
    "                   \"model_hdf5\":\"/data/locusselect/k562_dnase_dl_models/k562_classification/DNASE.K562.classification.SummitWithin200bpCenter.0\",\n",
    "                   \"ref_fasta\":\"/data/refs/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":True,\n",
    "                   \"flank\":125,\n",
    "                   \"embedding_layer\":layer,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20,\n",
    "                   \"global_pool_on_position\":True}\n",
    "        fc_regions, fc_embeddings = compute_embeddings(fc_embedding_args)\n",
    "        np.savez_compressed(bed_file.split('/')[-1]+'.fc.npz',bed_entries=fc_regions,fc_scores=fc_embeddings)\n",
    "        \n",
    "        dl_fc_data_list.append(fc_embeddings)\n",
    "        \n",
    "    return dl_fc_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_list = ['/users/soumya.kundu/locusselect/coordinates/'+x for x in os.listdir('/users/soumya.kundu/locusselect/coordinates/') if x.endswith('bed')]\n",
    "dl_bed_list = [BedTool(x) for x in bed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/coordinates/coordinates_5.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n",
      "9/9 [==============================] - 34s 4s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_1.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n",
      "5/5 [==============================] - 36s 7s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_3.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 34s 4s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_2.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n",
      "9/9 [==============================] - 34s 4s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_0.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n",
      "9/9 [==============================] - 35s 4s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_4.bed\n",
      "-2\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 1000, 300)      23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 1000, 300)      1200      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 1000, 300)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 333, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1, 333, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 333, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1, 333, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 83, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 83, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1, 83, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 20, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              4001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 5,977,301\n",
      "Trainable params: 5,971,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 35s 4s/step\n",
      "got embeddings\n",
      "got region labels\n"
     ]
    }
   ],
   "source": [
    "dl_fc_data_list = get_embedding_data_list_fc(bed_list, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/coordinates/coordinates_5.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 13s 1s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_1.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 12s 2s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_3.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 14s 2s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_2.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 14s 2s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_0.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 14s 2s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "/users/soumya.kundu/locusselect/coordinates/coordinates_4.bed\n",
      "1\n",
      "got model architecture\n",
      "loaded model weights\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_1\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1_input (InputLayer)  (None, 1, 250, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 250, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 250, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/soumya.kundu/locusselect/locusselect/embeddings/__init__.py:97: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"co..., outputs=Tensor(\"gl...)`\n",
      "  new_model = Model(input = model.input, output = flat_embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 9s 975ms/step\n",
      "got embeddings\n",
      "got region labels\n"
     ]
    }
   ],
   "source": [
    "dl_conv_data_list = get_embedding_data_list_conv(bed_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('class_conv_data_list.pickle', 'wb') as fp:\n",
    "#    pickle.dump(dl_conv_data_list, fp)\n",
    "\n",
    "#with open('class_fc_data_list.pickle', 'wb') as fp:\n",
    "#    pickle.dump(dl_fc_data_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('class_conv_data_list.pickle', 'rb') as fp:\n",
    "    dl_conv_data_list = pickle.load(fp)\n",
    "    \n",
    "with open ('class_fc_data_list.pickle', 'rb') as fp:\n",
    "    dl_fc_data_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceMeasure = 'correlation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_conv_embedding_list = performEmbeddings(dl_conv_data_list,metric=distanceMeasure)\n",
    "dl_fc_embedding_list = performEmbeddings(dl_fc_data_list,metric=distanceMeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_conv_embedding_list.pickle', 'wb') as fp:\n",
    "    pickle.dump(dl_conv_embedding_list, fp)\n",
    "\n",
    "with open('class_fc_embedding_list.pickle', 'wb') as fp:\n",
    "    pickle.dump(dl_fc_embedding_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('class_conv_embedding_list.pickle', 'rb') as fp:\n",
    "    dl_conv_embedding_list = pickle.load(fp)\n",
    "    \n",
    "with open ('class_fc_embedding_list.pickle', 'rb') as fp:\n",
    "    dl_fc_embedding_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding, file_ in zip(dl_conv_embedding_list, bed_list):\n",
    "    print(file_)\n",
    "    plot_embedding_2d(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding, file_ in zip(dl_fc_embedding_list, bed_list):\n",
    "    print(file_)\n",
    "    plot_embedding_2d(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_conv_SSIndex_list = []\n",
    "#for data in dl_conv_data_list:\n",
    "#    N = np.shape(data)[0]\n",
    "#    SubsetInds,gains = selectSubset( data, n = N, distance = 'corr' )\n",
    "#    dl_conv_SSIndex_list.append(SubsetInds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl_fc_SSIndex_list = []\n",
    "#for data in dl_fc_data_list:\n",
    "#    N = np.shape(data)[0]\n",
    "#    SubsetInds,gains = selectSubset( data, n = N, distance = 'corr' )\n",
    "#    dl_fc_SSIndex_list.append(SubsetInds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k562_ccREs = BedTool('/data/locusselect/k562_annotations/K562-ccREs.bed10.hg19Lifted.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_ccRESSIndex_list = []; histone_ccREIndex_list = []; histone_allccREIndex_list = []; histone_allccRESSIndex_list = [];\n",
    "for data,bed in zip(dl_fc_data_list,dl_bed_list):\n",
    "    N = np.shape(data)[0]\n",
    "    myintersect = bed.intersect(k562_ccREs, u=True, f=0.5, r=True)\n",
    "    a = [x for x in bed]\n",
    "    b = [y for y in myintersect]\n",
    "    c = []\n",
    "    for ind,val in enumerate(a):\n",
    "        if val in b:\n",
    "            c.append(ind)\n",
    "    ccRESubsetInds,ccREgains = selectSubset( data, n = ( N - len(c) ), distance = 'corr', initial_subset = c )\n",
    "    histone_ccRESSIndex_list.append(ccRESubsetInds); histone_ccREIndex_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_size = 50\n",
    "size_dict = { 'Subset' : 32, 'All' : 4, 'ccRE': 32 }\n",
    "alpha_dict = { 'Subset' : 1, 'All' : 0.125, 'ccRE': 1 }\n",
    "\n",
    "for SSIndex, embedding, ccRESSIndex, ix in zip (histone_ccREIndex_list,dl_fc_embedding_list,histone_ccRESSIndex_list, range(len(histone_ccRESSIndex_list))) :\n",
    "    num_labels, label_dict = makeGeneralAnnotation ( [ccRESSIndex[0:ss_size], SSIndex], \n",
    "        ['Subset', 'ccRE'], k = np.shape(embedding)[0] )\n",
    "    plot_embedding_2d(embedding, num_labels, label_dict, s_dict = size_dict, a_dict = alpha_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_ccRESSIndex_list = []; histone_ccREIndex_list = []; histone_allccREIndex_list = []; histone_allccRESSIndex_list = [];\n",
    "for data,bed in zip(dl_conv_data_list,dl_bed_list):\n",
    "    N = np.shape(data)[0]\n",
    "    myintersect = bed.intersect(k562_ccREs, u=True, f=0.5, r=True)\n",
    "    a = [x for x in bed]\n",
    "    b = [y for y in myintersect]\n",
    "    c = []\n",
    "    for ind,val in enumerate(a):\n",
    "        if val in b:\n",
    "            c.append(ind)\n",
    "    ccRESubsetInds,ccREgains = selectSubset( data, n = ( N - len(c) ), distance = 'corr', initial_subset = c )\n",
    "    histone_ccRESSIndex_list.append(ccRESubsetInds); histone_ccREIndex_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_size = 50\n",
    "size_dict = { 'Subset' : 32, 'All' : 4, 'ccRE': 32 }\n",
    "alpha_dict = { 'Subset' : 1, 'All' : 0.125, 'ccRE': 1 }\n",
    "\n",
    "for SSIndex, embedding, ccRESSIndex, ix in zip (histone_ccREIndex_list,dl_conv_embedding_list,histone_ccRESSIndex_list, range(len(histone_ccRESSIndex_list))) :\n",
    "    num_labels, label_dict = makeGeneralAnnotation ( [ccRESSIndex[0:ss_size], SSIndex], \n",
    "        ['Subset', 'ccRE'], k = np.shape(embedding)[0] )\n",
    "    plot_embedding_2d(embedding, num_labels, label_dict, s_dict = size_dict, a_dict = alpha_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_conv2_data_list = get_embedding_data_list_conv(bed_list, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_conv2_data_list.pickle', 'wb') as fp:\n",
    "    pickle.dump(dl_conv2_data_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('class_conv2_data_list.pickle', 'rb') as fp:\n",
    "    dl_conv2_data_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_conv2_embedding_list = performEmbeddings(dl_conv2_data_list,metric=distanceMeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_conv2_embedding_list.pickle', 'wb') as fp:\n",
    "    pickle.dump(dl_conv2_embedding_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('dl_conv2_embedding_list.pickle', 'rb') as fp:\n",
    "    dl_conv2_embedding_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding, file_ in zip(dl_conv2_embedding_list, bed_list):\n",
    "    print(file_)\n",
    "    plot_embedding_2d(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_ccRESSIndex_list = []; histone_ccREIndex_list = []; histone_allccREIndex_list = []; histone_allccRESSIndex_list = [];\n",
    "for data,bed in zip(dl_conv2_data_list,dl_bed_list):\n",
    "    N = np.shape(data)[0]\n",
    "    myintersect = bed.intersect(k562_ccREs, u=True, f=0.5, r=True)\n",
    "    a = [x for x in bed]\n",
    "    b = [y for y in myintersect]\n",
    "    c = []\n",
    "    for ind,val in enumerate(a):\n",
    "        if val in b:\n",
    "            c.append(ind)\n",
    "    ccRESubsetInds,ccREgains = selectSubset( data, n = ( N - len(c) ), distance = 'corr', initial_subset = c )\n",
    "    histone_ccRESSIndex_list.append(ccRESubsetInds); histone_ccREIndex_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_size = 50\n",
    "size_dict = { 'Subset' : 32, 'All' : 4, 'ccRE': 32 }\n",
    "alpha_dict = { 'Subset' : 1, 'All' : 0.125, 'ccRE': 1 }\n",
    "\n",
    "for SSIndex, embedding, ccRESSIndex, ix in zip (histone_ccREIndex_list,dl_conv2_embedding_list,histone_ccRESSIndex_list, range(len(histone_ccRESSIndex_list))) :\n",
    "    num_labels, label_dict = makeGeneralAnnotation ( [ccRESSIndex[0:ss_size], SSIndex], \n",
    "        ['Subset', 'ccRE'], k = np.shape(embedding)[0] )\n",
    "    plot_embedding_2d(embedding, num_labels, label_dict, s_dict = size_dict, a_dict = alpha_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkm_list = ['/data/locusselect/gkmexplain/'+x for x in os.listdir('/data/locusselect/gkmexplain/') if x.startswith('gkmexplain.coord.embeddings.')]\n",
    "gkm_data_list = []\n",
    "for i in gkm_list:\n",
    "    gkm_data_list.append(np.loadtxt(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8001, 5120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkm_data_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'axis' is an invalid keyword to ufunc 'absolute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0ebdedb43f07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgkm_data_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'axis' is an invalid keyword to ufunc 'absolute'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(np.sum(np.abs(gkm_data_list[0], axis=0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkm_embedding_list = performEmbeddings(gkm_data_list,metric=distanceMeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histone_ccRESSIndex_list = []; histone_ccREIndex_list = []; histone_allccREIndex_list = []; histone_allccRESSIndex_list = [];\n",
    "for data,bed in zip(gkm_data_list,dl_bed_list):\n",
    "    N = np.shape(data)[0]\n",
    "    myintersect = bed.intersect(k562_ccREs, u=True, f=0.5, r=True)\n",
    "    a = [x for x in bed]\n",
    "    b = [y for y in myintersect]\n",
    "    c = []\n",
    "    for ind,val in enumerate(a):\n",
    "        if val in b:\n",
    "            c.append(ind)\n",
    "    ccRESubsetInds,ccREgains = selectSubset( data, n = ( N - len(c) ), distance = 'corr', initial_subset = c )\n",
    "    histone_ccRESSIndex_list.append(ccRESubsetInds); histone_ccREIndex_list.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_size = 50\n",
    "size_dict = { 'Subset' : 32, 'All' : 4, 'ccRE': 32 }\n",
    "alpha_dict = { 'Subset' : 1, 'All' : 0.125, 'ccRE': 1 }\n",
    "\n",
    "for SSIndex, embedding, ccRESSIndex, ix in zip (histone_ccREIndex_list,gkm_embedding_list,histone_ccRESSIndex_list, range(len(histone_ccRESSIndex_list))) :\n",
    "    num_labels, label_dict = makeGeneralAnnotation ( [ccRESSIndex[0:ss_size], SSIndex], \n",
    "        ['Subset', 'ccRE'], k = np.shape(embedding)[0] )\n",
    "    plot_embedding_2d(embedding, num_labels, label_dict, s_dict = size_dict, a_dict = alpha_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "regression on 200 bp genome bins.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
