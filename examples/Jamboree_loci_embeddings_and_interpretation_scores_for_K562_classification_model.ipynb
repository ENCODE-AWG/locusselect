{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kundajelab/locusselect/blob/master/examples/regression%20on%20200%20bp%20genome%20bins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PlqtDJn5vLs4"
   },
   "outputs": [],
   "source": [
    "#load dragonn tutorial utilities \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.random import seed\n",
    "seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jFl7rUdvM8y"
   },
   "outputs": [],
   "source": [
    "#!pip install locusselect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHfRoZoAvLs8"
   },
   "source": [
    "## Classification K562 DNAse model (trained genomewide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DpEc9JvVvLs8"
   },
   "outputs": [],
   "source": [
    "## generate embeddings at the -2 layer \n",
    "import locusselect \n",
    "from locusselect.embeddings import * \n",
    "from locusselect.interpret import * \n",
    "from locusselect.utils import * \n",
    "from locusselect.gapped_kmers import * \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not transfer weights for layer:dense_4\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4_input (InputLayer)  (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "writing gzip-compressed output file:BCL11A.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13_input (InputLayer) (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_13\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13_input (InputLayer) (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "writing gzip-compressed output file:HBA2.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "created data generator\n",
      "10\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "writing output file\n",
      "created data generator\n",
      "10\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "writing output file\n",
      "created data generator\n",
      "10\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22_input (InputLayer) (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 22s 22s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_22\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22_input (InputLayer) (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "writing gzip-compressed output file:HBE1.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22_input (InputLayer) (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 30s 30s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_22\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22_input (InputLayer) (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 29s 29s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "writing gzip-compressed output file:LMO2.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28_input (InputLayer) (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 41s 41s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_28\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28_input (InputLayer) (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 37s 37s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "writing gzip-compressed output file:MYC.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7_input (InputLayer)  (None, 1, 1000, 4)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "=================================================================\n",
      "Total params: 5,576,300\n",
      "Trainable params: 5,570,900\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 49s 49s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 16s 16s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 16s 16s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 19s 19s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 13s 13s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "got model architecture\n",
      "loaded model weights\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 1, 982, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 982, 300)       1200      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1, 982, 300)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 327, 300)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 317, 200)       660200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1, 317, 200)       800       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1, 317, 200)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 79, 200)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 73, 200)        280200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 73, 200)        800       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1, 73, 200)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 18, 200)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1000)              3601000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 1001      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,577,301\n",
      "Trainable params: 5,571,901\n",
      "Non-trainable params: 5,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "loaded model\n",
      "Could not transfer weights for layer:dense_7\n",
      "obtained embedding layer model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7_input (InputLayer)  (None, 1, 500, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 482, 300)       23100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 482, 300)       1200      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 300)               0         \n",
      "=================================================================\n",
      "Total params: 24,300\n",
      "Trainable params: 23,700\n",
      "Non-trainable params: 600\n",
      "_________________________________________________________________\n",
      "None\n",
      "created data generator from 0\n",
      "1/1 [==============================] - 51s 51s/step\n",
      "created data generator from 1000\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "created data generator from 2000\n",
      "1/1 [==============================] - 10s 10s/step\n",
      "created data generator from 3000\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "created data generator from 4000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 5000\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "created data generator from 6000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 7000\n",
      "1/1 [==============================] - 11s 11s/step\n",
      "created data generator from 8000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "got embeddings\n",
      "got region labels\n",
      "writing output file\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "writing gzip-compressed output file:RBM38.gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\n",
      "generated gapped kmers\n",
      "got gapped kmer embedding function\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "Done 0\n",
      "Done 100\n",
      "Done 200\n",
      "Done 300\n",
      "Done 400\n",
      "Done 500\n",
      "Done 600\n",
      "Done 700\n",
      "Done 800\n",
      "Done 900\n",
      "Done 1000\n",
      "Done 1100\n",
      "Done 1200\n",
      "Done 1300\n",
      "Done 1400\n",
      "Done 1500\n",
      "Done 1600\n",
      "Done 1700\n",
      "Done 1800\n",
      "Done 1900\n",
      "Done 2000\n",
      "Done 2100\n",
      "Done 2200\n",
      "Done 2300\n",
      "Done 2400\n",
      "Done 2500\n",
      "Done 2600\n",
      "Done 2700\n",
      "Done 2800\n",
      "Done 2900\n",
      "Done 3000\n",
      "Done 3100\n",
      "Done 3200\n",
      "Done 3300\n",
      "Done 3400\n",
      "Done 3500\n",
      "Done 3600\n",
      "Done 3700\n",
      "Done 3800\n",
      "Done 3900\n",
      "Done 4000\n",
      "Done 4100\n",
      "Done 4200\n",
      "Done 4300\n",
      "Done 4400\n",
      "Done 4500\n",
      "Done 4600\n",
      "Done 4700\n",
      "Done 4800\n",
      "Done 4900\n",
      "Done 5000\n",
      "Done 5100\n",
      "Done 5200\n",
      "Done 5300\n",
      "Done 5400\n",
      "Done 5500\n",
      "Done 5600\n",
      "Done 5700\n",
      "Done 5800\n",
      "Done 5900\n",
      "Done 6000\n",
      "Done 6100\n",
      "Done 6200\n",
      "Done 6300\n",
      "Done 6400\n",
      "Done 6500\n",
      "Done 6600\n",
      "Done 6700\n",
      "Done 6800\n",
      "Done 6900\n",
      "Done 7000\n",
      "Done 7100\n",
      "Done 7200\n",
      "Done 7300\n",
      "Done 7400\n",
      "Done 7500\n",
      "Done 7600\n",
      "Done 7700\n",
      "Done 7800\n",
      "Done 7900\n",
      "Done 8000\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n",
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n"
     ]
    }
   ],
   "source": [
    "kmer_len=6\n",
    "num_gaps=1\n",
    "alphabet_size=4\n",
    "\n",
    "coord_prefix=\"/mnt/lab_data2/annashch/locusselect_examples/coordinates/Gurkan_hg19_loci_coords\"\n",
    "loci=[\"BCL11A\",\"HBA2\",\"HBE1\",\"LMO2\",\"MYC\",\"RBM38\"]\n",
    "splits=[1,4,7,7,9,2]\n",
    "for index in range(len(loci)):\n",
    "    locus=loci[index]\n",
    "    split=splits[index]\n",
    "    coords=coord_prefix+\"/\"+locus+\".geneLocus.250bp.windows.hg19.bed\"\n",
    "    #first, we get embeddings from the model fully connected layer \n",
    "    fc_embedding_args={\"input_bed_file\":coords,\n",
    "                   \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                   \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":False,\n",
    "                   \"center_on_bed_interval\":True,\n",
    "                   \"flank\":500,\n",
    "                   \"embedding_layer\":-3,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20,\n",
    "                   \"output_npz_file\":locus+\"_FC_layer_NN_embeddings.classification.npz\"}\n",
    "    fc_regions, fc_embeddings = compute_embeddings(fc_embedding_args)\n",
    "    \n",
    "    conv1_embedding_args={\"input_bed_file\":coords,\n",
    "                   \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                   \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":False,\n",
    "                   \"center_on_bed_interval\":True,\n",
    "                   \"flank\":250,\n",
    "                   \"embedding_layer\":1,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20,\n",
    "                   \"global_pool_on_position\":True,\n",
    "                   \"num_rows\":1000,\n",
    "                   \"output_npz_file\":locus+\"_CONV1_layer_NN_embeddings.npz\"}\n",
    "    conv1_regions, conv1_embeddings = compute_embeddings(conv1_embedding_args)\n",
    "    \n",
    "    gkmexplanations=\"/mnt/lab_data2/annashch/locusselect_examples/dataForGurkan/gkm_explain/gkm_explain_\"+locus+\".txt\"\n",
    "    imp_score_files=[gkmexplanations]\n",
    "    compute_gapped_kmer_embedding(kmer_len,\n",
    "                              num_gaps,\n",
    "                              alphabet_size,\n",
    "                              imp_score_files,\n",
    "                              outf=[locus+\".gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\"],\n",
    "                              batch_size=100)\n",
    "\n",
    "    kmer_embeddings=compute_gapped_kmer_embedding(kmer_len,\n",
    "                                         num_gaps,\n",
    "                                         alphabet_size,\n",
    "                                         imp_score_files,\n",
    "                                         outf=None,\n",
    "                                         batch_size=100)\n",
    "    #next, we get deepLIFT scores with 10 shuffled references  \n",
    "    deeplift_args={ \"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"deeplift_num_refs_per_seq\":10, #PLEASE SET THIS TO AT LEAST 10 IN PRACTISE!!!\n",
    "                \"deeplift_reference\":\"shuffled_ref\",\n",
    "                \"interpretation_layer\":-2,\n",
    "                \"output_npz_file\":locus+\".deepLIFT.shuffled.ref.10.npz\"}\n",
    "    deeplift_regions, deeplift_embeddings=compute_interpretation_scores(deeplift_args)\n",
    "    \n",
    "    deeplift_args={ \"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"deeplift_num_refs_per_seq\":10, #PLEASE SET THIS TO AT LEAST 10 IN PRACTISE!!!\n",
    "                \"deeplift_reference\":\"zero_ref\",\n",
    "                \"interpretation_layer\":-2,\n",
    "                \"output_npz_file\":locus+\".deepLIFT.zero.ref.npz\"}\n",
    "    deeplift_regions_zero_ref, deeplift_embeddings_zero_ref=compute_interpretation_scores(deeplift_args)\n",
    "\n",
    "    #next, we get deepLIFT scores with 0 reference \n",
    "    gradxinput_args={\"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"interpretation_layer\":-2,\n",
    "                \"input_grad\":True,\n",
    "                \"output_npz_file\":locus+\".input_grad.npz\"}\n",
    "    grad_regions, grad_embeddings=compute_interpretation_scores(gradxinput_args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuJnLIKWvLs_",
    "outputId": "09f5ec65-a426-4ad7-fb95-76cfb6514d8b"
   },
   "outputs": [],
   "source": [
    "#first, we get embeddings from the model fully connected layer \n",
    "fc_embedding_args={\"input_bed_file\":coords,\n",
    "                   \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                   \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":False,\n",
    "                   \"center_on_bed_interval\":True,\n",
    "                   \"flank\":500,\n",
    "                   \"embedding_layer\":-3,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20,\n",
    "                   \"output_npz_file\":locus+\"_FC_layer_NN_embeddings.classification.npz\"}\n",
    "\n",
    "fc_regions, fc_embeddings = compute_embeddings(fc_embedding_args)\n",
    "## alternatively, get the pre-generated embeddings \n",
    "#fc_regions,fc_embeddings,data_type=load_embedding(\"k562_dnase_regression_embeddings.0.-2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_regions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or execute for each locus individually "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First conv layer embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we get embeddings from the model fully connected layer \n",
    "conv1_embedding_args={\"input_bed_file\":coords,\n",
    "                   \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                   \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                   \"center_on_summit\":False,\n",
    "                   \"center_on_bed_interval\":True,\n",
    "                   \"flank\":250,\n",
    "                   \"embedding_layer\":1,\n",
    "                   \"expand_dims\":True,\n",
    "                   \"threads\":20,\n",
    "                   \"global_pool_on_position\":True,\n",
    "                   \"num_rows\":1000,\n",
    "                   \"output_npz_file\":locus+\"_CONV1_layer_NN_embeddings.npz\"}\n",
    "\n",
    "conv1_regions, conv1_embeddings = compute_embeddings(conv1_embedding_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GKM explain K-mer embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_len=6\n",
    "num_gaps=1\n",
    "alphabet_size=4\n",
    "gkmexplanations=\"/mnt/lab_data2/annashch/locusselect_examples/dataForGurkan/gkm_explain/gkm_explain_\"+locus+\".txt\"\n",
    "imp_score_files=[gkmexplanations]\n",
    "compute_gapped_kmer_embedding(kmer_len,\n",
    "                              num_gaps,\n",
    "                              alphabet_size,\n",
    "                              imp_score_files,\n",
    "                              outf=[locus+\".gapped.kmer.embeddings.kmer_len=6.num_gaps=1.alphabet_size=4.npz\"],\n",
    "                              batch_size=100)\n",
    "\n",
    "kmer_embeddings=compute_gapped_kmer_embedding(kmer_len,\n",
    "                                         num_gaps,\n",
    "                                         alphabet_size,\n",
    "                                         imp_score_files,\n",
    "                                         outf=None,\n",
    "                                         batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute deepLIFT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BylrjQ_tvLtD",
    "outputId": "8e0b4ea0-46ae-4e3f-9c13-e381bbc5321f"
   },
   "outputs": [],
   "source": [
    "#next, we get deepLIFT scores with 10 shuffled references  \n",
    "deeplift_args={ \"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"deeplift_num_refs_per_seq\":10, #PLEASE SET THIS TO AT LEAST 10 IN PRACTISE!!!\n",
    "                \"deeplift_reference\":\"shuffled_ref\",\n",
    "                \"deeplift_layer\":-2,\n",
    "                \"output_npz_file\":locus+\".deepLIFT.shuffled.ref.10.npz\"}\n",
    "deeplift_regions, deeplift_embeddings=compute_deeplift_scores(deeplift_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created data generator\n",
      "17\n",
      "0\n",
      "done with batch\n",
      "1\n",
      "done with batch\n",
      "2\n",
      "done with batch\n",
      "3\n",
      "done with batch\n",
      "4\n",
      "done with batch\n",
      "5\n",
      "done with batch\n",
      "6\n",
      "done with batch\n",
      "7\n",
      "done with batch\n",
      "8\n",
      "done with batch\n",
      "9\n",
      "done with batch\n",
      "10\n",
      "done with batch\n",
      "11\n",
      "done with batch\n",
      "12\n",
      "done with batch\n",
      "13\n",
      "done with batch\n",
      "14\n",
      "done with batch\n",
      "15\n",
      "done with batch\n",
      "16\n",
      "done with batch\n",
      "17\n",
      "writing output file\n"
     ]
    }
   ],
   "source": [
    "#next, we get deepLIFT scores with 0 reference \n",
    "deeplift_args={ \"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"deeplift_num_refs_per_seq\":10, #PLEASE SET THIS TO AT LEAST 10 IN PRACTISE!!!\n",
    "                \"deeplift_reference\":\"zero_ref\",\n",
    "                \"interpretation_layer\":-2,\n",
    "                \"output_npz_file\":locus+\".deepLIFT.zero.ref.npz\"}\n",
    "deeplift_regions_zero_ref, deeplift_embeddings_zero_ref=compute_interpretation_scores(deeplift_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sT06VIksvLtK",
    "outputId": "7e8f9e44-0e50-4bf5-843a-4b5d0f64a282"
   },
   "outputs": [],
   "source": [
    "print(fc_regions.shape)\n",
    "print(deeplift_regions.shape) \n",
    "print(fc_embeddings.shape)\n",
    "print(deeplift_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute grad x input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created data generator\n",
      "17\n",
      "0\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "1\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "2\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "3\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "4\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "5\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "6\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "7\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "8\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "9\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "10\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "11\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "12\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "13\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "14\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "15\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "16\n",
      "WARNING: this function provides aggregated gradients across tasks. Not recommended for multi-tasked models\n",
      "17\n",
      "writing output file\n"
     ]
    }
   ],
   "source": [
    "#next, we get deepLIFT scores with 0 reference \n",
    "gradxinput_args={\"input_bed_file\":coords,\n",
    "                \"model_hdf5\":\"/srv/scratch/annashch/deeplearning/encode4crispr/k562_dnase/classification/DNASE.K562.classification.SummitWithin200bpCenter.\"+str(split),\n",
    "                \"ref_fasta\":\"/mnt/data/annotations/by_release/hg19/male.hg19.fa\",\n",
    "                \"center_on_summit\":False,\n",
    "                \"center_on_bed_interval\":True,\n",
    "                \"flank\":500,\n",
    "                \"expand_dims\":True,\n",
    "                \"threads\":20,\n",
    "                \"task_index\":0,\n",
    "                \"batch_size\":500,\n",
    "                \"interpretation_layer\":-2,\n",
    "                \"input_grad\":True,\n",
    "                \"output_npz_file\":locus+\".input_grad.npz\"}\n",
    "grad_regions, grad_embeddings=compute_interpretation_scores(gradxinput_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mZJAwOy9vLtR"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Dimension reduction and clustering libraries\n",
    "import umap\n",
    "import hdbscan\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkdW9fvPvLtT"
   },
   "source": [
    "## UMAP clustering on fc layer embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oR5SESjgvLtU"
   },
   "outputs": [],
   "source": [
    "#we will randomly select 5000 peaks for clustering/visualizing (more than that takes a long time)\n",
    "n=5000 \n",
    "indices_for_clustering=np.random.choice(fc_embeddings.shape[0],n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_s2xsuovLtW"
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=42).fit_transform(fc_embeddings[indices_for_clustering])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtjcEtV-vLtZ",
    "outputId": "80c758da-9de6-4498-a5ac-c45dad04bb9d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.1, cmap='Spectral');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNbkkxv3vLtc"
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    ").fit_transform(fc_embeddings[indices_for_clustering])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29rBQmVZvLte",
    "outputId": "0d748d20-59c8-4035-f598-097e89d37a37"
   },
   "outputs": [],
   "source": [
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], s=0.1, cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tHeeWtGavLti"
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=10,\n",
    "    min_cluster_size=500,\n",
    "    \n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAfCPNZfvLtk",
    "outputId": "73476b68-1f67-4206-bcfb-42ce1db506d8"
   },
   "outputs": [],
   "source": [
    "#-1 means the regions were not clustered \n",
    "clustered = (labels >= 0)\n",
    "plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            s=0.1,\n",
    "            alpha=0.5)\n",
    "plt.scatter(standard_embedding[clustered, 0],\n",
    "            standard_embedding[clustered, 1],\n",
    "            c=labels[clustered],\n",
    "            s=0.1,\n",
    "            cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uAQFETXQvLto"
   },
   "outputs": [],
   "source": [
    "clustered_regions=fc_regions[indices_for_clustering]\n",
    "df=pd.DataFrame({'chrom':[i[0] for i in clustered_regions],\n",
    "                'start':[i[1] for i in clustered_regions],\n",
    "                'end':[i[2]for i in clustered_regions],\n",
    "                'labels':labels})\n",
    "#write to output bed file for analysis of motif enrichment in clusters \n",
    "df.to_csv(\"regression_fc_layer_embeddings_clusters.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKNr0Q8cvLtr"
   },
   "source": [
    "## UMAP clustering on deepLIFT scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfwbNxVvvLts",
    "outputId": "01259cd5-b2a4-4b93-93b6-409cf03058c9"
   },
   "outputs": [],
   "source": [
    "#We condense the deepLIFT scores to 2-D \n",
    "deeplift_embeddings=np.squeeze(deeplift_embeddings)\n",
    "#take the sum over the absolute value of the channel axis \n",
    "deeplift_embeddings_collapsed=np.sum(deeplift_embeddings,axis=-1)\n",
    "deeplift_embeddings_collapsed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc3cwUnjvLtw"
   },
   "outputs": [],
   "source": [
    "#we will randomly select 50000 peaks for clustering/visualizing (more than that takes a long time)\n",
    "n=5000 \n",
    "indices_for_clustering=np.random.choice(deeplift_embeddings_collapsed.shape[0],n) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TxKbbRfavLt1"
   },
   "outputs": [],
   "source": [
    "standard_embedding = umap.UMAP(random_state=42).fit_transform(deeplift_embeddings_collapsed[indices_for_clustering])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zumK0NVjvLt4",
    "outputId": "de6677a6-b15d-4f0e-acbd-85650eb3390c"
   },
   "outputs": [],
   "source": [
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=0.1, cmap='Spectral');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuKZYRXUvLt8"
   },
   "outputs": [],
   "source": [
    "clusterable_embedding = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    n_components=2,\n",
    "    random_state=42,\n",
    ").fit_transform(deeplift_embeddings_collapsed[indices_for_clustering])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbF3jeoKvLt-",
    "outputId": "555f4586-112e-4ed0-d378-547fb76eea4e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(clusterable_embedding[:, 0], clusterable_embedding[:, 1], s=0.1, cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aY0U7ah3vLuB"
   },
   "outputs": [],
   "source": [
    "labels = hdbscan.HDBSCAN(\n",
    "    min_samples=10,\n",
    "    min_cluster_size=500,\n",
    ").fit_predict(clusterable_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VkbaGNOOvLuD",
    "outputId": "7146d064-f1a2-48f9-ef09-5a1a999b9041"
   },
   "outputs": [],
   "source": [
    "#-1 means the \n",
    "clustered = (labels >= 0)\n",
    "plt.scatter(standard_embedding[~clustered, 0],\n",
    "            standard_embedding[~clustered, 1],\n",
    "            c=(0.5, 0.5, 0.5),\n",
    "            s=0.1,\n",
    "            alpha=0.5)\n",
    "plt.scatter(standard_embedding[clustered, 0],\n",
    "            standard_embedding[clustered, 1],\n",
    "            c=labels[clustered],\n",
    "            s=0.1,\n",
    "            cmap='Spectral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5O78dI2vLuG",
    "outputId": "23f1be3d-8a87-411e-f3ae-aed6c591f4e4"
   },
   "outputs": [],
   "source": [
    "deeplift_regions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55aov9BivLuI"
   },
   "outputs": [],
   "source": [
    "clustered_regions=deeplift_regions[indices_for_clustering]\n",
    "df=pd.DataFrame({'chrom':[i[0] for i in clustered_regions],\n",
    "                'start':[i[1] for i in clustered_regions],\n",
    "                'end':[i[2]for i in clustered_regions],\n",
    "                'labels':labels})\n",
    "#write to output bed file for analysis of motif enrichment in clusters \n",
    "df.to_csv(\"regression_deeplift_embeddings_clusters.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "regression on 200 bp genome bins.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
